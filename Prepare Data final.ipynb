{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:56:50.720793Z",
     "start_time": "2017-09-04T22:56:50.291621Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import calendar\n",
    "from os.path import join\n",
    "import json\n",
    "from urllib.parse import quote\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:56:50.780339Z",
     "start_time": "2017-09-04T22:56:50.722798Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load datasets from csvs\n",
    "train_raw = pd.read_csv(join('data', 'train.csv'),\n",
    "                    usecols=['Date', 'Species', 'Trap', 'Latitude', 'Longitude', 'NumMosquitos', 'WnvPresent'],\n",
    "                    dtype={'Trap': 'category'},\n",
    "                    parse_dates=['Date'])\n",
    "\n",
    "weather_raw = pd.read_csv(join('data', 'weather.csv'),\n",
    "                      parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:56:51.351390Z",
     "start_time": "2017-09-04T22:56:50.782338Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Water1 = 0 for all observations, drop it\n",
    "weather = weather_raw.drop(['Water1'], axis=1)\n",
    "# 'T' stands for 'trace amount' replace with 0 \n",
    "weather.replace('  T', 0, inplace=True)\n",
    "\n",
    "# Convert rows that are interpreted as object to numeric\n",
    "def numeric(x):\n",
    "    if x.dtype=='object' and x.name != 'CodeSum':\n",
    "        return pd.to_numeric(x, errors='coerce')\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "weather = weather.apply(numeric)\n",
    "\n",
    "# '-' represents a missing value\n",
    "weather.replace('-', np.NaN, inplace=True)\n",
    "\n",
    "# Replace the ResultDir, which is in degress, to sin and cos\n",
    "# which are cyclical\n",
    "weather['ResultDirSin'] = np.sin(np.radians(weather['ResultDir']))\n",
    "weather['ResultDirCos'] = np.cos(np.radians(weather['ResultDir']))\n",
    "weather.drop('ResultDir', axis=1, inplace=True)\n",
    "\n",
    "# 'TS', Thunderstorm, and 'FG' fog, are high moisture events\n",
    "# they might be useful. Drop other flags\n",
    "def findCodeSum(x, code):\n",
    "    if x.CodeSum.find(code) != -1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "weather['TS'] = weather.apply(findCodeSum, axis=1, code='TS', reduce=False)\n",
    "weather['FG'] = weather.apply(findCodeSum, axis=1, code='FG', reduce=False)\n",
    "\n",
    "weather.drop('CodeSum', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:56:51.387903Z",
     "start_time": "2017-09-04T22:56:51.353377Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate weather by station\n",
    "weather_stn1 = weather[weather['Station'] == 1]\n",
    "weather_stn2 = weather[weather['Station'] == 2]\n",
    "weather_stn1 = weather_stn1.drop('Station', axis=1).reset_index(drop=True)\n",
    "weather_stn2 = weather_stn2.drop('Station', axis=1).reset_index(drop=True)\n",
    "\n",
    "# Convert sunrise and sunset times to minutes past midnight\n",
    "weather_stn1['Sunrise'] = weather_stn1.Sunrise.apply(\n",
    "    lambda x: int(str(x)[:-4]) * 60 + int(str(x)[-4:-2]))\n",
    "weather_stn1['Sunset'] = weather_stn1.Sunset.apply(\n",
    "    lambda x: int(str(x)[:-4]) * 60 + int(str(x)[-4:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:56:55.836673Z",
     "start_time": "2017-09-04T22:56:51.391404Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create 20 days preceding averages of some features\n",
    "to_mean = ['Tmax', 'Tmin', 'Tavg', 'Depart', 'DewPoint', 'WetBulb', \n",
    "           'Heat', 'Cool', 'Depth', 'SnowFall', 'PrecipTotal', 'ResultSpeed',\n",
    "           'ResultDirSin', 'ResultDirCos', 'AvgSpeed']\n",
    "\n",
    "for feature in to_mean:\n",
    "    \n",
    "    tmp = []\n",
    "    for i in range(len(weather_stn1)):\n",
    "        tmp.append(np.mean(weather_stn1[feature].iloc[max(0, i-20):i+1]))\n",
    "    weather_stn1[feature+'Mean'] = tmp\n",
    "    \n",
    "    tmp = []\n",
    "    for i in range(len(weather_stn2)):\n",
    "        tmp.append(np.mean(weather_stn2[feature].iloc[max(0, i-20):i+1]))\n",
    "    weather_stn2[feature+'Mean'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:56:55.896223Z",
     "start_time": "2017-09-04T22:56:55.838677Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate days since the last rain\n",
    "days = 0\n",
    "DaysSinceRain = []\n",
    "\n",
    "for row in weather_stn1.itertuples():\n",
    "    DaysSinceRain.append(days)\n",
    "    if row.PrecipTotal == 0:\n",
    "        days += 1\n",
    "    else:\n",
    "        days = 0\n",
    "        \n",
    "weather_stn1['DaysSinceRain'] = DaysSinceRain\n",
    "\n",
    "days = 0\n",
    "DaysSinceRain = []\n",
    "\n",
    "for row in weather_stn2.itertuples():\n",
    "    DaysSinceRain.append(days)\n",
    "    if row.PrecipTotal == 0:\n",
    "        days += 1\n",
    "    else:\n",
    "        days = 0\n",
    "        \n",
    "weather_stn2['DaysSinceRain'] = DaysSinceRain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:56:55.994299Z",
     "start_time": "2017-09-04T22:56:55.902227Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find rotation matrix that places the two weather stations\n",
    "# on a single axis\n",
    "p1 = np.array([-87.933, 41.995])\n",
    "p2 = np.array([-87.752, 41.786])\n",
    "p = p1 - p2\n",
    "\n",
    "angle = np.arctan((p[0])/(p[1]))\n",
    "rot_mat = [[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]]\n",
    "\n",
    "p_dist = np.matmul(rot_mat, p)[1]\n",
    "\n",
    "# This function will take a date and trap location,\n",
    "# rotate the map so that the stations are one one axis\n",
    "# then calculate the linear interpolation of the weather\n",
    "# at the two stations, and assign the corresponding weather data\n",
    "# at the y coordinate of the trap\n",
    "def weather_gen(date, lat, lon):\n",
    "    \n",
    "    return_data = pd.DataFrame()\n",
    "\n",
    "    x = np.array([lon, lat]) - p2\n",
    "    x_dist = np.matmul(rot_mat, x)[1]\n",
    "    \n",
    "    w1 = weather_stn1[weather_stn1.Date==date]\n",
    "    w2 = weather_stn2[weather_stn2.Date==date]\n",
    "    \n",
    "    if len(w1) != 1 or len(w2) != 1:\n",
    "        raise ValueError('Too many values for single date')\n",
    "    \n",
    "    for col in weather_stn1.columns[1:]:\n",
    "        if col in ['DaysSinceRain', 'TS', 'FG']:\n",
    "            if x_dist > p_dist:\n",
    "                return_data[col] = w1[col].values\n",
    "            else:\n",
    "                return_data[col] = w2[col].values\n",
    "        elif any(pd.isnull(w1[col])):\n",
    "            return_data[col] = w2[col].values\n",
    "        elif any(pd.isnull(w2[col])):\n",
    "            return_data[col] = w1[col].values\n",
    "        else:\n",
    "            return_data[col] = [np.interp(x_dist, [0, p_dist], np.append(w2[col], w1[col]))]\n",
    "    \n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:58:49.601217Z",
     "start_time": "2017-09-04T22:56:55.997302Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find all unique date and location pairs in the dataset\n",
    "weather_combos = train_raw[['Date', 'Latitude', 'Longitude']].groupby(\n",
    "    ['Date', 'Latitude', 'Longitude']).count().reset_index()\n",
    "\n",
    "# Calculate the weather for all the combos\n",
    "weather_tmp = pd.DataFrame(columns=weather.columns[2:])\n",
    "\n",
    "for row in weather_combos.itertuples():\n",
    "    weather_tmp = weather_tmp.append(\n",
    "        weather_gen(row.Date, row.Latitude, row.Longitude), ignore_index=True)\n",
    "\n",
    "weather_data = pd.concat([weather_combos, weather_tmp], axis=1)\n",
    "\n",
    "# Make sure that some features don't get converted to object\n",
    "weather_data['TS'] = weather_data.TS.astype(int)\n",
    "weather_data['FG'] = weather_data.FG.astype(int)\n",
    "\n",
    "weather_data['Sunrise'] = weather_data.Sunrise.astype(int)\n",
    "weather_data['Sunset'] = weather_data.Sunset.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:58:49.617731Z",
     "start_time": "2017-09-04T22:58:49.603721Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will calculate the zone of a location\n",
    "# data is acquired from Chicago Data Portal\n",
    "# using their SODA api, return 0 if there is no\n",
    "# data for the location\n",
    "def get_zone(lat, lon):\n",
    "    query = (\"https://data.cityofchicago.org/resource/dj47-wfun.geojson?\"+\n",
    "             \"$$app_token=DktAvFbM8ptYxalNeI1J4OvgP&$where=intersects(the_geom,\"+\n",
    "             quote(f\" 'POINT ({lon} {lat})')\"))\n",
    "    response = urlopen(query)\n",
    "    data = json.loads(response.read().decode('utf-8'))\n",
    "    \n",
    "    if not data['features']:\n",
    "        return 0\n",
    "    else:\n",
    "        return int(data['features'][0]['properties']['zone_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:59:14.463144Z",
     "start_time": "2017-09-04T22:58:49.620733Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find zone for all traps\n",
    "trap_zones = []\n",
    "\n",
    "traps = train_raw[['Trap', 'Latitude', 'Longitude']]\n",
    "\n",
    "for trap in traps.Trap.astype('category').cat.categories:\n",
    "    trap_zones.append([\n",
    "        trap, get_zone(traps[traps.Trap == trap].iloc[0].Latitude,\n",
    "                       traps[traps.Trap == trap].iloc[0].Longitude)\n",
    "    ])\n",
    "\n",
    "trap_zones = pd.DataFrame(trap_zones, columns=['Trap', 'Zone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:59:14.478121Z",
     "start_time": "2017-09-04T22:59:14.465133Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count how many times a trap is split for a certain date, trap, and species\n",
    "train_trap_count = train_raw.groupby(\n",
    "    ['Date', 'Trap', 'Species']).size().reset_index().rename(\n",
    "        columns={0: 'TrapCount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:59:14.487153Z",
     "start_time": "2017-09-04T22:59:14.480624Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These three species are the only ones that have been detected\n",
    "# with the virus\n",
    "valid_species = ['CULEX PIPIENS/RESTUANS', 'CULEX PIPIENS','CULEX RESTUANS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:59:14.512468Z",
     "start_time": "2017-09-04T22:59:14.489452Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code the species data into one hot, only keeping the valid species\n",
    "train_species = pd.get_dummies(train_raw.Species, prefix='', prefix_sep='')\n",
    "train_species = train_species[valid_species]\n",
    "\n",
    "train = train_raw.join(train_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:59:14.570511Z",
     "start_time": "2017-09-04T22:59:14.516472Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge all mosquito, calculated weather, and trap zone information\n",
    "train = train.merge(\n",
    "    train_trap_count, on=['Date', 'Trap', 'Species'], how='left').merge(\n",
    "        trap_zones, on=['Trap'], how='left').merge(\n",
    "            weather_data, on=['Date', 'Latitude', 'Longitude'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:59:14.589531Z",
     "start_time": "2017-09-04T22:59:14.572511Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code zone into one hot variables\n",
    "train_zone_one_hot = pd.get_dummies(train.Zone, prefix='Zone', prefix_sep='', drop_first=True)\n",
    "\n",
    "train = train.join(train_zone_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:59:14.665584Z",
     "start_time": "2017-09-04T22:59:14.594535Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code month into one hot\n",
    "train_month_one_hot = pd.get_dummies(\n",
    "    train.Date.apply(lambda x: x.month),\n",
    "    prefix='',\n",
    "    prefix_sep='',\n",
    "    drop_first=True)\n",
    "train_month_one_hot.columns = [\n",
    "    calendar.month_abbr[int(x)] for x in train_month_one_hot.columns\n",
    "]\n",
    "\n",
    "train = train.join(train_month_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:59:14.779687Z",
     "start_time": "2017-09-04T22:59:14.669589Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code year into one hot\n",
    "train_year_one_hot = pd.get_dummies(\n",
    "    train.Date.apply(lambda x: x.year),\n",
    "    prefix='',\n",
    "    prefix_sep='',\n",
    "    drop_first=True)\n",
    "\n",
    "train = train.join(train_year_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-04T22:59:14.808586Z",
     "start_time": "2017-09-04T22:59:14.784696Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save new datasets\n",
    "pd.to_pickle(train.pickle, 'train')\n",
    "\n",
    "pd.to_pickle(trap_zones.pickle, 'trap_zones')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
